\abstract{This work presents a two-stage framework to assist physicians by efficiently retrieving and summarizing relevant medical literature. Using the PMC-Patients dataset, our system employs a RoBERTa-based encoder to map patient descriptions to pertinent research articles, while symptom extraction is performed using SciSpaCy to isolate key clinical features. Retrieved full-text articles are preprocessed and segmented to accommodate GPU memory constraints, then summarized using a fine-tuned large language model based on the LLaMA architecture. Evaluation with metrics such as BLEU, ROUGE, METEOR, and BERTScore indicates that although the model effectively captures semantic meaning, it falls short in lexical accuracy and overall structural coherence. Overfitting and data imbalance, compounded by hardware limitations, further constrain performance. Despite these challenges, our approach demonstrates potential in alleviating the cognitive burden on doctors by rapidly synthesizing crucial insights from expansive medical records. Future improvements will focus on enhancing symptom extraction precision, optimizing training strategies, and exploring more advanced LLMs to deliver clinically robust decision support.}